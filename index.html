<!DOCTYPE HTML>
<!--
	Miniport by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->

<html>
	<head>
		<title>SiTH</title>
		<meta charset="utf-8" />

        
		<meta name="viewport" content="width=device-width, initial-scale=1" />
        <link rel="stylesheet" href="assets/css/bulma.min.css">
        <link rel="stylesheet" href="assets/css/bulma-carousel.min.css">
        <link rel="stylesheet" href="assets/css/bulma-slider.min.css">
        <link rel="stylesheet" href="assets/css/bootstrap.min.css">
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
        <link rel="stylesheet" href="assets/css/font-awesome.min.css">
        <link rel="stylesheet" href="assets/css/index.css">
        <link rel="stylesheet" href="assets/css/style.css" type="text/css" media="screen,projection" />
        <link rel="stylesheet" href="assets/css/main.css" />
        <link rel="shortcut icon" href="images/opt_icon.png" />

        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
        <script src="assets/js/bulma-carousel.min.js"></script>
        <script src="assets/js/bulma-slider.min.js"></script>
        <script src="assets/js/index.js"></script>
        <script src="assets/js/video_comparison.js"></script>

	</head>
	<body>

		<!-- Home -->
        <div class="wrapper first style1">
            <article class="container" id="home">
                <img class="responsive-img" src="images/icon/sith.png" width="300px">
                <h2> Single-view Textured Human Reconstruction <br> with Image-Conditioned Diffusion</h2>
                <br>
                <div class="row center">
                    <div class="author col l4 m6 s12"><a href="https://azuxmioy.github.io/" target="_blank">Hsuan-I Ho</a></div>
                    <div class="author col l4 m6 s12"><a href="https://ait.ethz.ch/people/song" target="_blank">Jie Song</a></div>
                    <div class="author col l4 m6 s12"><a href="https://ait.ethz.ch/people/hilliges" target="_blank">Otmar Hilliges</a></div>
                </div>
                <br>
                <div class="col">
                    <div style="width: 20%; margin: 0em auto 0em auto">
                        <a  href="https://ait.ethz.ch/"><img class="responsive-img" src="images/ait_logo.png"></a>
                    </div>
                    <div class="institute">
                        <a href="https://inf.ethz.ch/" target="_blank">Department of Computer Science</a>,
                        <a href="https://ethz.ch/en.html" target="_blank">ETH Zürich</a>
                    </div>

                </div>
                <br>

                <div class="row">
                    <div class="col-sm-6 col-sm-offset-3 text-center">
                        <ul class="nav nav-pills nav-justified">
                            <li>
                                <a href="https://arxiv.org/abs/2311.15855">
                                    <img src="images/icon/darth.png" width="60px">
                                    <h4><strong>Paper<br>(CVPR 2024)</strong></h4>
                                </a>
                            </li>
                            <li>
                                <a href="https://youtu.be/gixakzI9UcM">
                                <img src="images/icon/Yt_icon_2017_print.png" width="60px">
                                    <h4><strong>Video</strong></h4>
                                </a>
                            </li>                       
                            <li>
                                <a href="https://github.com/SiTH-Diffusion/SiTH" target="_blank">
                                    <image src="images/icon/github.png" width="60px">
                                    <h4><strong>Code<br></strong></h4>
                                </a>
                            </li>
                            <li>
                                <a href="https://ait.ethz.ch/sith-demo" target="_blank">
                                    <image src="images/icon/hf.png" width="60px">
                                    <h4><strong>Demo<br></strong></h4>
                                </a>
                            </li>
                        </ul>
                    </div>
                </div>
            </article>

            <div class="container" style="width:40%; margin: 2em auto 2em auto">
                <h2>News:</h2>
                <h4>[June 14, 2024] Release training scripts.</h4>
                <h4>[May 15, 2024] Update an application of 3D avatar animation.</h4>
                <h4>[April 24, 2024] Gradio demo for 3D human creation is now available.</h4>
                <h4>[April 15, 2024] Release demo code, models, and the evaluation benchmark.</h4>
            </div>
        </div>


		<!-- Abstract -->
        <div class="wrapper style1">
            <article id="abstract">
                <div class="container">

                    <h2>TL;DR</h2>
                    <ul class="default" style="text-align:left">
                        <li>SiTH is a <b>non-optimization</b> single-view 3D reconstruction pipeline integrating a novel <b>image-conditioned ControlNet model</b> and implicit neural fields.</li>
                        <li>SiTH reconstructs a <b>fully-textured</b> and high-quality 3D human mesh from a single image in <b>2 minutes</b>.</li>
                        <li>SiTH can be trained with as few as <b>500 3D human scans</b> and generalizes well to diverse images such as AI-generated images. (<b>Check out our demo!</b>)</li>
                        <li>To foster future research, we contribute a <b>new evaluation benchmark</b> for single-view 3D human reconstruction.</li>
                    </ul>

                    <div class="row center" style="width: 100%; margin: 2em auto 2em auto">
                        <div class="col s10 offset-s1">
                            <img class="responsive-img" src="images/teaser.jpg" style="width: 100%"/>
                        </div>                    
                    </div>  
                    <h2>Abstract</h2>
                    <p style="text-align:justify">
                        A long-standing goal of 3D human reconstruction is to create lifelike and fully detailed 3D humans from single-view images. 
                        The main challenge lies in inferring unknown body shapes, appearances, and clothing details in areas not visible in the images. 
                        To address this, we propose SiTH, a novel pipeline that uniquely integrates an image-conditioned diffusion model into a 3D mesh reconstruction workflow. 
                        At the core of our method lies the decomposition of the challenging single-view reconstruction problem into generative hallucination and reconstruction subproblems. 
                        For the former, we employ a powerful generative diffusion model to hallucinate unseen back-view appearance based on the input images. 
                        For the latter, we leverage skinned body meshes as guidance to recover full-body texture meshes from the input and back-view images. 
                        SiTH requires as few as 500 3D human scans for training while maintaining its generality and robustness to diverse images. 
                        Extensive evaluations on two 3D human benchmarks, including our newly created one, highlighted our method's superior accuracy and perceptual quality in 3D textured human reconstruction. 
                    </p>
                </div>
            </article>
        </div>
		<!-- Paper -->
        <div class="wrapper style1">
            <article id="paper">
                <div class="container">
                
                    <h2>Video</h2>

                    <div class="row center" style="margin: 2em auto 2em auto">
                        <div class="col s10 offset-s1">
                            <div class="youtube-wrapper">
                                <iframe allowfullscreen="allowfullscreen" src="https://www.youtube.com/embed/gixakzI9UcM"></iframe>
                            </div>
                        </div>
                    </div>
                    
                    <h2>Method Overview</h2>
                    <div class="row center" style="width: 100%; margin: 2em auto 2em auto">
                        <div class="col s10 offset-s1">
                            <img class="responsive-img" src="images/framework.jpg" style="width: 100%"/>
                        </div>    
                    </div>

                    <h3>Hallucination and Reconstruction</h3>
                    <p style="text-align:justify">
                        At the core of SiTH is the decomposition of the challenging single-view problem into two subproblems: 
                        generative back-view hallucination and mesh reconstruction. For hallucination, we harness the generative 
                        capabilities of diffusion models to infer unobserved back-view appearances from the input images. 
                        For reconstruction, we utilize a skinned body mesh, providing essential 3D guidance for accurate human mesh reconstruction. 
                        This decomposition strategy allows our pipeline to be trained efficiently with just 500 3D scans, 
                        while still robustly handling unseen images.
                    </p>

                    <div class="row center" style="width: 100%; margin: 2em auto 2em auto">
                        <div class="col s6 offset-s3">
                            <img class="responsive-img" src="images/diffusion.jpg" style="width: 100%"/>
                        </div>                    
                    </div>

                    <h3>Image-conditioned Diffusion</h3>
                    <p style="text-align:justify">
                        Compared to text-conditioning in traditional diffusion models, our image-conditioning strategy is more consistent and accurate, 
                        allowing for building a data-driven 3D reconstruction pipeline. First, the pretrained CLIP and VAE encoders ensure the output images 
                        maintain visual consistency with the front-view images. Additionally, we render UV maps from the SMPL-X body mesh and extract 
                        silhouette masks from the back-view images. These additional conditional controls ensure the human poses in the output images match 
                        those in the front view. To preserve the diffusion model's generative power, we specifically optimize the ControlNet and 
                        cross-attention layers with only a small amount of 3D human data.
                    </p>
                    
                </div>
            </article>
        </div>

        <!-- Results -->

        <div class="wrapper style1">
            <article id="results">
                <div class="container">
                    <h2>Results</h2>
                    <h3>Single-view 3D Human Reconstruction</h3>
                    <div class="row center" style="width: 100%; margin: 1em auto 1em auto" >
                        <div class="col l4 m6 s12 text-center">
                            <video class="video" id="mesh1" loop autoplay muted src="videos/000.mp4" onplay="resizeAndPlay(this)"></video>
                            <canvas height=0 class="videoMerge" id="mesh1Merge"></canvas>
                            <br>
                            <a onclick="document.getElementById('input000').click();">Show input image</a>
                            <img class="materialboxed responsive-img" src="images/000.jpg" id="input000"/>

                        </div>
                        <div class="col l4 m6 s12 text-center">
                            <video class="video" id="mesh2" loop autoplay muted src="videos/001.mp4" onplay="resizeAndPlay(this)"></video>
                            <canvas height=0 class="videoMerge" id="mesh2Merge"></canvas>
                            <br>
                            <a onclick="document.getElementById('input001').click();">Show input image</a>
                            <img class="materialboxed responsive-img" src="images/001.jpg" id="input001"/>
                        </div>
                        <div class="col l4 m6 s12 text-center">
                            <video class="video" id="mesh3" loop autoplay muted src="videos/002.mp4" onplay="resizeAndPlay(this)"></video>
                            <canvas height=0 class="videoMerge" id="mesh3Merge"></canvas>
                            <br>
                            <a onclick="document.getElementById('input002').click();">Show input image</a>
                            <img class="materialboxed responsive-img" src="images/002.jpg" id="input002"/>
                        </div>
                    </div>
                    <div class="row center" style="width: 100%; margin: 1em auto 1em auto" >
                        <div class="col l4 m6 s12 text-center">
                            <video class="video" id="mesh4" loop autoplay muted src="videos/003.mp4" onplay="resizeAndPlay(this)"></video>
                            <canvas height=0 class="videoMerge" id="mesh4Merge"></canvas>
                            <br>
                            <a onclick="document.getElementById('input003').click();">Show input image</a>
                            <img class="materialboxed responsive-img" src="images/003.jpg" id="input003"/>
                        </div>
                        <div class="col l4 m6 s12 text-center">
                            <video class="video" id="mesh5" loop autoplay muted src="videos/004.mp4" onplay="resizeAndPlay(this)"></video>
                            <canvas height=0 class="videoMerge" id="mesh5Merge"></canvas>
                            <br>
                            <a onclick="document.getElementById('input004').click();">Show input image</a>
                            <img class="materialboxed responsive-img" src="images/004.jpg" id="input004"/>
                        </div>
                        <div class="col l4 m6 s12 text-center">
                            <video class="video" id="mesh6" loop autoplay muted src="videos/005.mp4" onplay="resizeAndPlay(this)"></video>
                            <canvas height=0 class="videoMerge" id="mesh6Merge"></canvas>
                            <br>
                            <a onclick="document.getElementById('input005').click();">Show input image</a>
                            <img class="materialboxed responsive-img" src="images/005.jpg" id="input005"/>
                        </div>
                    </div>

                    <div class="row center" style="width: 100%; margin: 1em auto 1em auto" >
                        <div class="col l4 m6 s12 text-center">
                            <video class="video" id="mesh7" loop autoplay muted src="videos/006.mp4" onplay="resizeAndPlay(this)"></video>
                            <canvas height=0 class="videoMerge" id="mesh7Merge"></canvas>
                            <br>
                            <a onclick="document.getElementById('input006').click();">Show input image</a>
                            <img class="materialboxed responsive-img" src="images/006.jpg" id="input006"/>
                        </div>
                        <div class="col l4 m6 s12 text-center">
                            <video class="video" id="mesh8" loop autoplay muted src="videos/007.mp4" onplay="resizeAndPlay(this)"></video>
                            <canvas height=0 class="videoMerge" id="mesh8Merge"></canvas>
                            <br>
                            <a onclick="document.getElementById('input007').click();">Show input image</a>
                            <img class="materialboxed responsive-img" src="images/007.jpg" id="input007"/>
                        </div>
                        <div class="col l4 m6 s12 text-center">
                            <video class="video"  id="mesh9" loop autoplay muted src="videos/008.mp4" onplay="resizeAndPlay(this)"></video>
                            <canvas height=0 class="videoMerge" id="mesh9Merge"></canvas>
                            <br>
                            <a onclick="document.getElementById('input008').click();">Show input image</a>
                            <img class="materialboxed responsive-img" src="images/008.jpg" id="input008"/>
                        </div>
                    </div>

                    <h3>Text-guided 3D Human Creation</h3>

                    <div class="row center" style="width: 50%; margin: 2em auto 2em auto">
                        <div class="col s6 offset-s3">
                            <img class="responsive-img" src="images/sith_demo.gif" style="width: 100%"/>
                        </div>
                    </div>
                    <h4 style="text-align: center">SiTH can be easily combined with powerful 2D text-to-image models.</h4>

                    <div class="row center" style="width: 100%; margin: 1em auto 1em auto" >
                        <div class="col l4 m6 s12 text-center">
                            <video class="video" id="mesh10" loop autoplay muted src="videos/011.mp4" onplay="resizeAndPlay(this)"></video>
                            <canvas height=0 class="videoMerge" id="mesh10Merge"></canvas>
                            <br>
                            "A male wearing a white suit"
                        </div>
                        <div class="col l4 m6 s12 text-center">
                            <video class="video" id="mesh11" loop autoplay muted src="videos/012.mp4" onplay="resizeAndPlay(this)"></video>
                            <canvas height=0 class="videoMerge" id="mesh11Merge"></canvas>
                            <br>
                            "A man wearing brown t-shirt and pants"
                        </div>
                        <div class="col l4 m6 s12 text-center">
                            <video class="video" id="mesh12" loop autoplay muted src="videos/013.mp4" onplay="resizeAndPlay(this)"></video>
                            <canvas height=0 class="videoMerge" id="mesh12Merge"></canvas>
                            <br>
                            "A woman in a white t-shirt and a tennis skirt"
                        </div>
                    </div>

                    <h3>3D Avatars</h3>

                    <div class="row center " style="width: 75%; margin: 2em auto 2em auto">
                        <div class="col s12">
                            <img class="responsive-img" src="images/animation.gif" style="width: 100%"/>
                        </div>
                    </div>
                    <h4 style="text-align: center">SiTH can easily create animation-ready 3D avatars from images.</h4>

                </div> 
            </article>
        </div>

        <!-- Download -->

        <div class="wrapper style1">
            <article id="benchmark">
                <div class="container">
                    <h2>Benchmark Evaluation</h2>
                    The benchmark is based on the <a href="https://custom-humans.github.io/#download" target="_blank">CustomHumans</a> dataet. To access the benchmark, please apply the dataset directly.
                    <br>
                    <br>
                    <h3>Single-view 3D Human Reconstruction</h3>
                    <div class="table-wrapper" align="center">
                        <table>
                            <thead>
                                <tr>
                                    <th>Methods</th>
                                    <th>P-to-S (cm) ↓</th>
                                    <th>S-to-P (cm) ↓</th>
                                    <th>NC ↑</th>
                                    <th>f-Score ↑</th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr>
                                    <td><h6>PIFu <a href="https://github.com/shunsukesaito/PIFu">[Saito2019]</a></h6></td>
                                    <td>2.209</td>
                                    <td>2.582</td>
                                    <td>0.805</td>
                                    <td>34.881</td>
                                </tr>
                                <tr>
                                    <td><h6>PIFuHD <a href="https://github.com/facebookresearch/pifuhd">[Saito2020]</a></h6></td>
                                    <td>2.107</td>
                                    <td><ins>2.228</ins></td>
                                    <td>0.804</td>
                                    <td><strong>39.076</strong></td>
                                </tr>
                                <tr>
                                    <td><h6>PaMIR <a href="https://github.com/ZhengZerong/PaMIR">[Zheng2021]</a></h6></td>
                                    <td>2.181</td>
                                    <td>2.507</td>
                                    <td><ins>0.813</ins></td>
                                    <td>35.847</td>
                                </tr>
                                <tr>
                                    <td><h6>FOF <a href="https://github.com/fengq1a0/FOF">[Feng2022]</a></h6></td>
                                    <td><ins>2.079</ins></td>
                                    <td>2.644</td>
                                    <td>0.808</td>
                                    <td>36.013</td>
                                </tr>
                                <tr>
                                    <td><h6>2K2K <a href="https://github.com/SangHunHan92/2K2K">[Han2023]</a></h6></td>
                                    <td>2.488</td>
                                    <td>3.292</td>
                                    <td>0.796</td>
                                    <td>30.186</td>
                                </tr>
                                <tr>
                                    <td><h6>ICON* <a href="https://github.com/YuliangXiu/ICON">[Xiu2022]</a></h6></td>
                                    <td>2.256</td>
                                    <td>2.795</td>
                                    <td>0.791</td>
                                    <td>30.437</td>
                                </tr>
                                <tr>
                                    <td><h6>ECON* <a href="https://github.com/fengq1a0/FOF">[Xiu2023]</a></h6></td>
                                    <td>2.483</td>
                                    <td>2.680</td>
                                    <td>0.797</td>
                                    <td>30.894</td>
                                </tr>
                                <tr>
                                    <td><h6>SiTH* (Ours)</h6></td>
                                    <td><strong>1.871</strong></td>
                                    <td><strong>2.045</strong></td>
                                    <td><strong>0.826</strong></td>
                                    <td><ins>37.029</ins></td>
                                </tr>
                            </tbody>
                        </table>
                        <h4>*indicates methods trained on the same THuman2.0 dataset.</h4>
                    </div>

                    <div class="row center" style="width: 100%; margin: 2em auto 2em auto">
                        <div class="col s12">
                            <img class="responsive-img" src="images/benchmark_3D.jpg" style="width: 100%"/>
                        </div>                    
                    </div>

                    <h3>Comparison with Optimization-based (Score Distillation) Approaches</h3>


                    <div class="row center" style="width: 100%; margin: 1em auto 1em auto" >
                        <div class="col l4 m6 s12 text-center">
                            <video class="video" id="mesha" loop autoplay muted src="videos/a.mp4" onplay="resizeAndPlay(this)"></video>
                            <canvas height=0 class="videoMerge" id="meshaMerge"></canvas>
                            <br>
                            <h5>Zero-1-to-3, 10 mins<h5>
                        </div>
                        <div class="col l4 m6 s12 text-center">
                            <video class="video" id="meshb" loop autoplay muted src="videos/b.mp4" onplay="resizeAndPlay(this)"></video>
                            <canvas height=0 class="videoMerge" id="meshbMerge"></canvas>
                            <br>
                            <h5>Magic-1-to-3, 6 hours<h5>
                        </div>
                        <div class="col l4 m6 s12 text-center">
                            <video class="video" id="meshc" loop autoplay muted src="videos/c.mp4" onplay="resizeAndPlay(this)"></video>
                            <canvas height=0 class="videoMerge" id="meshcMerge"></canvas>
                            <br>
                            <h5>TeCH, 6 hours<h5>
                        </div>
                    </div>

                    <div class="row center" style="width: 100%; margin: 1em auto 1em auto" >
                        <div class="col l6 m6 s12 text-center">
                            <video class="video" id="meshd" loop autoplay muted src="videos/d.mp4" onplay="resizeAndPlay(this)"></video>
                            <canvas height=0 class="videoMerge" id="meshdMerge"></canvas>
                            <br>
                            <h5>SiTH (Ours), 2 mins<h5>
                        </div>
                        <div class="col l6 m6 s12 text-center">
                            <video class="video" id="meshe" loop autoplay muted src="videos/e.mp4" onplay="resizeAndPlay(this)"></video>
                            <canvas height=0 class="videoMerge" id="mesheMerge"></canvas>
                            <br>
                            <h5>GT Reference<h5>
                        </div>
                    </div>

                    <div class="row center" style="width: 70%; margin: 2em auto 2em auto">
                        <div class="col s12">
                            <img class="responsive-img" src="images/vs_tech.jpg" style="width: 100%"/>
                        </div>
                        <h4>Compared to optimization-based methods (Score Distillation), 
                            SiTH reconstructs consistent facial textures that align with the input images and their underlying geometry.</h4>
                 
                    </div>


            </article>
        </div>



        <!-- Reference -->
        <div class="wrapper style2">
            <article id="references" class="container">
                <header>
                    <h3>References</h3>
                </header>
                <ul class="default" style="text-align:left">
                    <li>
                        Ho et. al, "<a href="https://custom-humans.github.io/" target="_blank">Learning Locally Editable Virtual Humans</a>." CVPR, 2023.
                    </li>
                    <li>
                        Kim et. al, "<a href="https://snuvclab.github.io/chupa/" target="_blank">Chupa : Carving 3D Clothed Humans from Skinned Shape Priors using 2D Diffusion Probabilistic Models</a>." ICCV, 2023.
                    </li>
                    <li>
                        Liu et. al, "<a href="https://zero123.cs.columbia.edu/" target="_blank">Zero-1-to-3: Zero-shot One Image to 3D Object</a>." ICCV, 2023.
                    </li>
                    <li>
                        Qian et. al, "<a href="https://guochengqian.github.io/project/magic123/" target="_blank">Magic123: One Image to High-Quality 3D Object Generation Using Both 2D and 3D Diffusion Priors</a>." ICLR, 2024.
                    </li>
                    <li>
                        Huang et. al, "<a href="https://huangyangyi.github.io/TeCH/" target="_blank">TeCH: Text-guided Reconstruction of Lifelike Clothed Humans</a>." 3DV, 2024.
                    </li>
                </ul>
                <div class="subtitle">
                    <h3>Bibtex</h3>
<pre><cite>@inproceedings{ho2024sith,
    title={SiTH: Single-view Textured Human Reconstruction with Image-Conditioned Diffusion},
    author={Ho, Hsuan-I and Song, Jie and Hilliges, Otmar},
    booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
    year={2024}
  }</cite></pre>
                </div>
            </article>


            
        </div>

        <!-- Acknowledgement -->
        <div class="wrapper style3">
            <article>
                <div class="container">
                    <h2>Acknowledgement</h2>
                    <p  style="text-align:left">
                        This work was partially supported by the Swiss SERI Consolidation Grant "AI-PERCEIVE". 
                        We thank Xu Chen for insightful discussions, Manuel Kaufmann for suggestions on writing and the title, 
                        and Christoph Gebhardt, Marcel Buehler, and Juan-Ting Lin for their writing advice.</p>
                </div>
            </article>
        </div>
      
        <!-- Copyright -->
        <div class="wrapper last style4">
            <article class="container">
                <footer>
                    <ul id="copyright">
                        <li>&copy; 2023 Hsuan-I Ho.</li><li>Thanks: <a href="http://html5up.net" target="_blank">HTML5 UP</a> and Po-Chen Wu provides this template</li>
                    </ul>
                </footer>
            </article>
        </div>

		<!-- Scripts -->
        <script src="assets/js/jquery.min.js"></script>
        <script src="assets/js/jquery.scrolly.min.js"></script>
        <script src="assets/js/skel.min.js"></script>
        <script src="assets/js/skel-viewport.min.js"></script>
        <script src="assets/js/util.js"></script>
        <script src="assets/js/main.js"></script>
        <script src="assets/js/materialize.js"></script>
    </body>
</html>
